{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Success vs. Total Average Episodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each model across ALL tasks and trials:\n",
        "\n",
        "1. TOTAL AVERAGE EPISODES:\n",
        "   - Total episodes = sum of all episode counts across all trials for that model\n",
        "   - Total trials = count of all trials for that model  \n",
        "   - Total avg episodes = total episodes / total trials\n",
        "   \n",
        "   This gives us the average number of episodes a model needs per trial,\n",
        "   aggregated across all tasks it attempted.\n",
        "\n",
        "2. SUCCESS RATE:\n",
        "   - Successful trials = count of trials where reward = 1\n",
        "   - Success rate = successful trials / total trials\n",
        "   \n",
        "   This gives us the proportion of trials where the model succeeded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from pathlib import Path\n",
        "from scipy import stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_episode_data():\n",
        "    # TODO: Set path to your terminus2 data directory (output from get_terminus2_runs.py)\n",
        "    episode_file = Path(\"../../../terminus2_9-17_essential_files/episode_counts.json\")\n",
        "    \n",
        "    with open(episode_file, 'r') as f:\n",
        "        episode_data = json.load(f)\n",
        "    \n",
        "    df = pd.DataFrame(episode_data)\n",
        "    \n",
        "    required_columns = ['trial_id', 'episode_count', 'model_name', 'task_name', 'reward']\n",
        "    df = df[df[required_columns].notna().all(axis=1)].copy()\n",
        "    df = df[df['episode_count'] >= 0].copy()\n",
        "    \n",
        "    return df\n",
        "\n",
        "df = load_episode_data()\n",
        "print(f\"Loaded {len(df)} valid trials\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_model_statistics(df):\n",
        "    model_stats = []\n",
        "    \n",
        "    for model_name in df['model_name'].unique():\n",
        "        model_data = df[df['model_name'] == model_name]\n",
        "        \n",
        "        total_episodes = model_data['episode_count'].sum()\n",
        "        total_trials = len(model_data)\n",
        "        successful_trials = len(model_data[model_data['reward'] == 1])\n",
        "        success_rate = successful_trials / total_trials if total_trials > 0 else 0\n",
        "        \n",
        "        model_stats.append({\n",
        "            'model_name': model_name,\n",
        "            'total_episodes': total_episodes,\n",
        "            'total_trials': total_trials,\n",
        "            'successful_trials': successful_trials,\n",
        "            'success_rate': success_rate\n",
        "        })\n",
        "    \n",
        "    stats_df = pd.DataFrame(model_stats)\n",
        "    stats_df = stats_df.sort_values('success_rate', ascending=False)\n",
        "    \n",
        "    return stats_df\n",
        "\n",
        "stats_df = calculate_model_statistics(df)\n",
        "display(stats_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simplify_model_name(model_name):\n",
        "    model_names = {\n",
        "        \"claude-sonnet-4-20250514\": \"Claude Sonnet 4\",\n",
        "        \"claude-opus-4-1-20250805\": \"Claude Opus 4.1\",\n",
        "        \"gpt-5\": \"GPT-5\",\n",
        "        \"gpt-5-mini\": \"GPT-5-Mini\",\n",
        "        \"gpt-5-nano\": \"GPT-5-Nano\",\n",
        "        \"grok-4-0709\": \"Grok 4\",\n",
        "        \"grok-code-fast-1\": \"Grok Code Fast 1\",\n",
        "        \"gemini-2.5-pro\": \"Gemini 2.5 Pro\",\n",
        "        \"gemini-2.5-flash\": \"Gemini 2.5 Flash\",\n",
        "        \"Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8\": \"Qwen 3 Coder 480B\",\n",
        "        \"openai/gpt-oss-120b\": \"GPT-OSS 120B\",\n",
        "        \"OpenAI/gpt-oss-20B\": \"GPT-OSS 20B\",\n",
        "        \"moonshotai/Kimi-K2-Instruct-0905\": \"Kimi K2\",\n",
        "        \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\": \"Llama 4 Maverick 17B\",\n",
        "        \"zai-org/GLM-4.5-Air-FP8\": \"GLM 4.5 Air\",\n",
        "        \"deepseek-ai/DeepSeek-V3.1\": \"DeepSeek V3.1\",\n",
        "    }\n",
        "    return model_names.get(model_name, model_name)\n",
        "\n",
        "def extract_provider_from_model(model_name):\n",
        "    if 'claude' in model_name.lower():\n",
        "        return 'Anthropic'\n",
        "    elif 'gpt' in model_name.lower() or 'openai' in model_name.lower():\n",
        "        return 'OpenAI'\n",
        "    elif 'gemini' in model_name.lower():\n",
        "        return 'Google'\n",
        "    elif 'deepseek' in model_name.lower():\n",
        "        return 'DeepSeek'\n",
        "    elif 'kimi' in model_name.lower() or 'moonshot' in model_name.lower():\n",
        "        return 'Moonshot'\n",
        "    elif 'qwen' in model_name.lower():\n",
        "        return 'Alibaba'\n",
        "    elif 'grok' in model_name.lower():\n",
        "        return 'xAI'\n",
        "    elif 'glm' in model_name.lower() or 'zai-org' in model_name.lower():\n",
        "        return 'Zhipu'\n",
        "    elif 'llama' in model_name.lower() or 'meta' in model_name.lower():\n",
        "        return 'Meta'\n",
        "    else:\n",
        "        return 'Other'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_scatter_plot(stats_df):\n",
        "    fig, ax = plt.subplots(figsize=(14, 10))\n",
        "    \n",
        "    stats_df = stats_df.copy()\n",
        "    stats_df['provider'] = stats_df['model_name'].apply(extract_provider_from_model)\n",
        "    \n",
        "    provider_colors = {\n",
        "        'OpenAI': '#d62728',\n",
        "        'Anthropic': '#2ca02c',\n",
        "        'Google': '#ff7f0e',\n",
        "        'xAI': '#bcbd22',\n",
        "        'DeepSeek': '#9467bd',\n",
        "        'Meta': '#8c564b',\n",
        "        'Moonshot': '#e377c2',\n",
        "        'Alibaba': '#7f7f7f',\n",
        "        'Zhipu': '#17becf',\n",
        "        'Other': '#1f77b4'\n",
        "    }\n",
        "    \n",
        "    stats_df['total_avg_episodes'] = stats_df['total_episodes'] / stats_df['total_trials']\n",
        "    \n",
        "    for provider in stats_df['provider'].unique():\n",
        "        provider_data = stats_df[stats_df['provider'] == provider]\n",
        "        ax.scatter(provider_data['total_avg_episodes'], provider_data['success_rate'],\n",
        "                  c=provider_colors.get(provider, '#95A5A6'), \n",
        "                  label=provider, s=100, alpha=0.7, edgecolors='black', linewidth=1)\n",
        "    \n",
        "    x = stats_df['total_avg_episodes']\n",
        "    y = stats_df['success_rate']\n",
        "    \n",
        "    correlation, p_value = stats.pearsonr(x, y)\n",
        "    \n",
        "    z = np.polyfit(x, y, 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax.plot(x, p(x), \"r--\", alpha=0.8, linewidth=2, \n",
        "            label=f'Trend Line (r={correlation:.3f}, p={p_value:.3f})')\n",
        "    \n",
        "    for _, row in stats_df.iterrows():\n",
        "        display_name = simplify_model_name(row['model_name'])\n",
        "        x_pos = row['total_avg_episodes']\n",
        "        y_pos = row['success_rate']\n",
        "        \n",
        "        base_offset = (-8, 0)\n",
        "        if display_name == 'Grok 4':\n",
        "            base_offset = (8, 8)\n",
        "        \n",
        "        ha = 'right' if base_offset[0] < 0 else 'left'\n",
        "        \n",
        "        ax.annotate(display_name, \n",
        "                   (x_pos, y_pos),\n",
        "                   xytext=base_offset, textcoords='offset points',\n",
        "                   fontsize=10, ha=ha, va='center')\n",
        "    \n",
        "    ax.set_xlabel('Total Average Episodes', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Success Rate', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Total Average Episodes vs Success Rate', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.2f}'))\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_xlim(left=0)\n",
        "    ax.set_ylim(bottom=0, top=max(stats_df['success_rate']) * 1.1)\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('total_avg_episodes_vs_success.png', dpi=300, bbox_inches='tight')\n",
        "    plt.savefig('total_avg_episodes_vs_success.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    return correlation, p_value\n",
        "\n",
        "correlation, p_value = create_scatter_plot(stats_df)\n",
        "print(f\"Correlation: {correlation:.3f}, p-value: {p_value:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats_df.to_csv('model_total_statistics.csv', index=False)\n",
        "print(f\"Saved statistics for {len(stats_df)} models\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
